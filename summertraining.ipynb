{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhEJtFfa_lVC",
        "outputId": "1c1ebe0a-878f-4c7b-c76f-a84c05388921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (200, 6)\n",
            "   TimeOnSite   Age  Gender  AdsClicked  PreviousPurchases  Purchase\n",
            "0    8.467391  41.0  Female         8.0                3.0       1.0\n",
            "1   18.816166  41.0  Female         7.0                1.0       0.0\n",
            "2    7.457470  18.0    Male         1.0                NaN       1.0\n",
            "3   11.136754  63.0    Male         NaN                2.0       0.0\n",
            "4    5.102389  55.0  Female         3.0                2.0       1.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, roc_auc_score, classification_report\n",
        ")\n",
        "from sklearn.utils import resample\n",
        "import joblib\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_excel(\"product_purchase_.xlsx\")\n",
        "print(\"Shape:\", df.shape)\n",
        "print(df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2xh3fRtY_sHs"
      },
      "outputs": [],
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "df.fillna(df.median(numeric_only=True), inplace=True)\n",
        "df.fillna(df.mode().iloc[0], inplace=True)\n",
        "\n",
        "\n",
        "if 'Gender' in df.columns:\n",
        "    le = LabelEncoder()\n",
        "    df['Gender'] = le.fit_transform(df['Gender'].astype(str))\n",
        "else:\n",
        "    le = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JClwV4N___IS",
        "outputId": "6b320a99-61f2-4496-b15e-29de4bb7104b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Class distribution before balancing:\n",
            "Purchase\n",
            "0    113\n",
            "1     87\n",
            "Name: count, dtype: int64\n",
            "\n",
            " Dataset already balanced or nearly balanced.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "target_col = None\n",
        "for c in df.columns:\n",
        "    if c.lower() in ['purchase', 'bought', 'target', 'label']:\n",
        "        target_col = c\n",
        "        break\n",
        "if target_col is None:\n",
        "    raise ValueError(\" No target column found! Add a 'Purchase' or 'Bought' column.\")\n",
        "\n",
        "\n",
        "if df[target_col].nunique() > 2:\n",
        "    df[target_col] = (df[target_col] > 0).astype(int)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nClass distribution before balancing:\")\n",
        "print(df[target_col].value_counts())\n",
        "\n",
        "df_majority = df[df[target_col] == 0]\n",
        "df_minority = df[df[target_col] == 1]\n",
        "\n",
        "if len(df_minority) > 0 and len(df_majority) / len(df_minority) > 1.5:\n",
        "    df_minority_upsampled = resample(\n",
        "        df_minority,\n",
        "        replace=True,\n",
        "        n_samples=len(df_majority),\n",
        "        random_state=42\n",
        "    )\n",
        "    df = pd.concat([df_majority, df_minority_upsampled])\n",
        "    print(\"\\n Dataset balanced using upsampling.\")\n",
        "else:\n",
        "    print(\"\\n Dataset already balanced or nearly balanced.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KCe0fwo4Af5A"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "X = df.drop(columns=[target_col])\n",
        "y = df[target_col]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YIsGXZAKAxDh"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y_pred_log = log_reg.predict(X_test_scaled)\n",
        "y_pred_tree = tree.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXcnrZWhA6O3",
        "outputId": "2a65cdc9-e5b4-429e-c099-4df765e0fba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Logistic Regression PERFORMANCE\n",
            "Accuracy  : 0.6250\n",
            "Precision : 0.5714\n",
            "Recall    : 0.2500\n",
            "F1-score  : 0.3478\n",
            "ROC-AUC   : 0.5625\n",
            "Confusion Matrix:\n",
            " [[21  3]\n",
            " [12  4]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.88      0.74        24\n",
            "           1       0.57      0.25      0.35        16\n",
            "\n",
            "    accuracy                           0.62        40\n",
            "   macro avg       0.60      0.56      0.54        40\n",
            "weighted avg       0.61      0.62      0.58        40\n",
            "\n",
            "\n",
            " Decision Tree PERFORMANCE\n",
            "Accuracy  : 0.5750\n",
            "Precision : 0.4706\n",
            "Recall    : 0.5000\n",
            "F1-score  : 0.4848\n",
            "ROC-AUC   : 0.5625\n",
            "Confusion Matrix:\n",
            " [[15  9]\n",
            " [ 8  8]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.62      0.64        24\n",
            "           1       0.47      0.50      0.48        16\n",
            "\n",
            "    accuracy                           0.57        40\n",
            "   macro avg       0.56      0.56      0.56        40\n",
            "weighted avg       0.58      0.57      0.58        40\n",
            "\n",
            "\n",
            "MODEL COMPARISON SUMMARY\n",
            "                 Model  Accuracy  F1 Score\n",
            "0  Logistic Regression     0.625  0.347826\n",
            "1        Decision Tree     0.575  0.484848\n",
            "\n",
            "Best Performing Model: Logistic Regression\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def evaluate_model(name, y_true, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    auc = roc_auc_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\n {name} PERFORMANCE\")\n",
        "    print(f\"Accuracy  : {acc:.4f}\")\n",
        "    print(f\"Precision : {prec:.4f}\")\n",
        "    print(f\"Recall    : {rec:.4f}\")\n",
        "    print(f\"F1-score  : {f1:.4f}\")\n",
        "    print(f\"ROC-AUC   : {auc:.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
        "\n",
        "\n",
        "    return acc, prec, rec, f1, auc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "evaluate_model(\"Logistic Regression\", y_test, y_pred_log)\n",
        "evaluate_model(\"Decision Tree\", y_test, y_pred_tree)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    \"Model\": [\"Logistic Regression\", \"Decision Tree\"],\n",
        "    \"Accuracy\": [\n",
        "        accuracy_score(y_test, y_pred_log),\n",
        "        accuracy_score(y_test, y_pred_tree)\n",
        "    ],\n",
        "    \"F1 Score\": [\n",
        "        f1_score(y_test, y_pred_log),\n",
        "        f1_score(y_test, y_pred_tree)\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\nMODEL COMPARISON SUMMARY\")\n",
        "print(results)\n",
        "best_model = results.loc[results['Accuracy'].idxmax(), 'Model']\n",
        "print(f\"\\nBest Performing Model: {best_model}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YI9oj4lFBAPX"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "joblib.dump(log_reg, \"model.joblib\")\n",
        "joblib.dump(scaler, \"scaler.joblib\")\n",
        "if le:\n",
        "    joblib.dump(le, \"le_gender.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "JmKBdm9s0209",
        "outputId": "24640cbd-66b5-4681-f690-68be8313cb35"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\CHINTAPALLI SIVA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "c:\\Users\\CHINTAPALLI SIVA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\CHINTAPALLI SIVA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\CHINTAPALLI SIVA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\CHINTAPALLI SIVA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\CHINTAPALLI SIVA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\CHINTAPALLI SIVA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\CHINTAPALLI SIVA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\CHINTAPALLI SIVA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\CHINTAPALLI SIVA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\CHINTAPALLI SIVA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\CHINTAPALLI SIVA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\CHINTAPALLI SIVA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\CHINTAPALLI SIVA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    import gradio as gr\n",
        "except ModuleNotFoundError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"gradio\"])\n",
        "    import gradio as gr\n",
        "\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "model = joblib.load(\"model.joblib\")\n",
        "scaler = joblib.load(\"scaler.joblib\")\n",
        "le = joblib.load(\"le_gender.joblib\")\n",
        "\n",
        "def predict_purchase(time_on_site, age, gender, ads_clicked, prev_purchases):\n",
        "    if gender not in le.classes_:\n",
        "        return \"‚ùå Invalid gender. Choose Male, Female, or Other.\"\n",
        "    g = le.transform([gender])[0]\n",
        "    X = np.array([[time_on_site, age, g, ads_clicked, prev_purchases]])\n",
        "    X_scaled = scaler.transform(X)\n",
        "    prob = model.predict_proba(X_scaled)[0][1]\n",
        "    pred = model.predict(X_scaled)[0]\n",
        "    result = \"‚úÖ Will Buy\" if pred == 1 else \"‚ùå Will Not Buy\"\n",
        "    return f\"{result} (Probability: {prob:.2f})\"\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=predict_purchase,\n",
        "    inputs=[\n",
        "        gr.Number(label=\"Time on Website (minutes)\"),\n",
        "        gr.Number(label=\"Age\"),\n",
        "        gr.Radio([\"Male\", \"Female\", \"Other\"], label=\"Gender\"),\n",
        "        gr.Number(label=\"Ads Clicked\"),\n",
        "        gr.Number(label=\"Previous Purchases\")\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"üõí Product Purchase Likelihood Predictor\",\n",
        "    description=\"Enter customer details to predict if they will buy the product.\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "interface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XodwySOPQ5mt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
